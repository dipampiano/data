{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ThiccShady.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmmDYXv-TtX1",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI13bSw17Siu",
        "colab_type": "text"
      },
      "source": [
        "**Importing relevant modules in this space of all kinds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DyPya1lyPe_",
        "colab_type": "code",
        "outputId": "75bdc046-c4f7-4e91-af0f-c499a593a54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "!pip install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-cp36-none-any.whl size=6085 sha256=8c2a833f1f9f74fa49ba3abb46e0f7eb0f1251443e59d8700ac41c48c48c49a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/68/c3/a05a35f647ba871e5572b9bbfc0b95fd1c6637a2219f959e7a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84tnQffp_nRu",
        "colab_type": "code",
        "outputId": "066f0b2e-0974-4be5-9f3d-6081d9fe5412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "!pip install pescador"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pescador\n",
            "  Downloading https://files.pythonhosted.org/packages/75/64/df7b03e8bf0edbf2a07e4666f0b5879919009a73f54f0a828adfe122c0a8/pescador-2.1.0.tar.gz\n",
            "Requirement already satisfied: joblib>=0.9 in /usr/local/lib/python3.6/dist-packages (from pescador) (0.14.1)\n",
            "Requirement already satisfied: six>=1.8 in /usr/local/lib/python3.6/dist-packages (from pescador) (1.12.0)\n",
            "Requirement already satisfied: pyzmq>=15.0 in /usr/local/lib/python3.6/dist-packages (from pescador) (17.0.0)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from pescador) (1.17.4)\n",
            "Requirement already satisfied: decorator>=4.0 in /usr/local/lib/python3.6/dist-packages (from pescador) (4.4.1)\n",
            "Building wheels for collected packages: pescador\n",
            "  Building wheel for pescador (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pescador: filename=pescador-2.1.0-cp36-none-any.whl size=21076 sha256=d62f6c962108e9bc40fa878d509a7f78eddc7ccf1da9724bdf672b4b62869e1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/e7/2d/de501314d1f03d8607aed0f6b48e50d8699f681745003aaa5b\n",
            "Successfully built pescador\n",
            "Installing collected packages: pescador\n",
            "Successfully installed pescador-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee6dus2l_sRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "def check_memory():\n",
        "    return torch.cuda.memory_allocated()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsUNekCRxDEf",
        "colab_type": "code",
        "outputId": "8818db55-ab3c-4240-978e-7d86d82bdf93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2POq-h7-6Q3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#======================== Network based imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch import autograd\n",
        "from torch import optim\n",
        "\n",
        "#=========================Training related imports\n",
        "import json\n",
        "import numpy as np\n",
        "import pprint\n",
        "import pickle\n",
        "import datetime\n",
        "\n",
        "#========================== utility imports\n",
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import logging\n",
        "import librosa\n",
        "import argparse\n",
        "import pescador\n",
        "import ffmpeg\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY2hkuIAztNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67UJ_3yPT2v3",
        "colab_type": "text"
      },
      "source": [
        "# NETWORKS AND NORMS (ARCHITECTURE BASED CELLS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGYQMmMg7dBg",
        "colab_type": "text"
      },
      "source": [
        "**Transpose1d layer**  (The 8 minute video we saw. This is the convolution for audio type data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y01A14Y6hm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Transpose1dLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=11, upsample=None, output_padding=1):\n",
        "        super(Transpose1dLayer, self).__init__()\n",
        "        self.upsample = upsample\n",
        "\n",
        "        self.upsample_layer = torch.nn.Upsample(scale_factor=upsample)\n",
        "        reflection_pad = kernel_size // 2\n",
        "        self.reflection_pad = nn.ConstantPad1d(reflection_pad, value=0)\n",
        "        self.conv1d = torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride)\n",
        "        self.Conv1dTrans = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.upsample:\n",
        "            return self.conv1d(self.reflection_pad(self.upsample_layer(x)))\n",
        "        else:\n",
        "            return self.Conv1dTrans(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PhaseShuffle(nn.Module):\n",
        "    \"\"\"\n",
        "    Performs phase shuffling, i.e. shifting feature axis of a 3D tensor\n",
        "    by a random integer in {-n, n} and performing reflection padding where\n",
        "    necessary.\n",
        "    \"\"\"\n",
        "    # Copied from https://github.com/jtcramer/wavegan/blob/master/wavegan.py#L8\n",
        "    def __init__(self, shift_factor):\n",
        "        super(PhaseShuffle, self).__init__()\n",
        "        self.shift_factor = shift_factor\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.shift_factor == 0:\n",
        "            return x\n",
        "        # uniform in (L, R)\n",
        "        k_list = torch.Tensor(x.shape[0]).random_(0, 2 * self.shift_factor + 1) - self.shift_factor\n",
        "        k_list = k_list.numpy().astype(int)\n",
        "\n",
        "        # Combine sample indices into lists so that less shuffle operations\n",
        "        # need to be performed\n",
        "        k_map = {}\n",
        "        for idx, k in enumerate(k_list):\n",
        "            k = int(k)\n",
        "            if k not in k_map:\n",
        "                k_map[k] = []\n",
        "            k_map[k].append(idx)\n",
        "\n",
        "        # Make a copy of x for our output\n",
        "        x_shuffle = x.clone()\n",
        "\n",
        "        # Apply shuffle to each sample\n",
        "        for k, idxs in k_map.items():\n",
        "            if k > 0:\n",
        "                x_shuffle[idxs] = F.pad(x[idxs][..., :-k], (k, 0), mode='reflect')\n",
        "            else:\n",
        "                x_shuffle[idxs] = F.pad(x[idxs][..., -k:], (0, -k), mode='reflect')\n",
        "\n",
        "        assert x_shuffle.shape == x.shape, \"{}, {}\".format(x_shuffle.shape,\n",
        "                                                       x.shape)\n",
        "        return x_shuffle\n",
        "\n",
        "\n",
        "class PhaseRemove(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PhaseRemove, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "# \"\"\"\n",
        "# from torch.autograd import Variable\n",
        "# x = Variable(torch.randn(10, 100))\n",
        "# G = WaveGANGenerator(verbose=True, upsample=False)\n",
        "# out = G(x)\n",
        "# print(out.shape)\n",
        "# D = WaveGANDiscriminator(verbose=True)\n",
        "# out2 = D(out)\n",
        "# print(out2.shape)\n",
        "# \"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCf1IUfw7r34",
        "colab_type": "text"
      },
      "source": [
        "***Generator*** class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcyEyjZO7IsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WaveGANGenerator(nn.Module):\n",
        "    def __init__(self, model_size=64, ngpus=1, num_channels=1,\n",
        "                 latent_dim=100, post_proc_filt_len=512,\n",
        "                 verbose=False, upsample=True):\n",
        "        super(WaveGANGenerator, self).__init__()\n",
        "        self.ngpus = ngpus\n",
        "        self.model_size = model_size  # d\n",
        "        self.num_channels = num_channels  # c\n",
        "        self.latent_di = latent_dim\n",
        "        self.post_proc_filt_len = post_proc_filt_len\n",
        "        self.verbose = verbose\n",
        "        # \"Dense\" is the same meaning as fully connection.\n",
        "        self.fc1 = nn.Linear(latent_dim, 256 * model_size)\n",
        "\n",
        "        stride = 4\n",
        "        if upsample:\n",
        "            stride = 1\n",
        "            upsample = 4\n",
        "        self.deconv_1 = Transpose1dLayer(16 * model_size, 8 * model_size, 25, stride, upsample=upsample)\n",
        "        self.deconv_2 = Transpose1dLayer(8 * model_size, 4 * model_size, 25, stride, upsample=upsample)\n",
        "        self.deconv_3 = Transpose1dLayer(4 * model_size, 2 * model_size, 25, stride, upsample=upsample)\n",
        "        self.deconv_4 = Transpose1dLayer(2 * model_size, model_size, 25, stride, upsample=upsample)\n",
        "        self.deconv_5 = Transpose1dLayer(model_size, num_channels, 25, stride, upsample=upsample)\n",
        "\n",
        "        if post_proc_filt_len:\n",
        "            self.ppfilter1 = nn.Conv1d(num_channels, num_channels, post_proc_filt_len)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x).view(-1, 16 * self.model_size, 16)\n",
        "        x = F.relu(x)\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "\n",
        "        x = F.relu(self.deconv_1(x))\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "\n",
        "        x = F.relu(self.deconv_2(x))\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "\n",
        "        x = F.relu(self.deconv_3(x))\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "\n",
        "        x = F.relu(self.deconv_4(x))\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "\n",
        "        output = torch.tanh(self.deconv_5(x))\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9gvTn7Y7vHf",
        "colab_type": "text"
      },
      "source": [
        "***Discriminator*** Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNmwK4N27Qo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WaveGANDiscriminator(nn.Module):\n",
        "    def __init__(self, model_size=64, ngpus=1, num_channels=1, shift_factor=2,\n",
        "                 alpha=0.2, verbose=False):\n",
        "        super(WaveGANDiscriminator, self).__init__()\n",
        "        self.model_size = model_size  # d\n",
        "        self.ngpus = ngpus\n",
        "        self.num_channels = num_channels  # c\n",
        "        self.shift_factor = shift_factor  # n\n",
        "        self.alpha = alpha\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.conv1 = nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11)\n",
        "        self.conv2 = nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11)\n",
        "        self.conv3 = nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11)\n",
        "        self.conv4 = nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11)\n",
        "        self.conv5 = nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11)\n",
        "\n",
        "        self.ps1 = PhaseShuffle(shift_factor)\n",
        "        self.ps2 = PhaseShuffle(shift_factor)\n",
        "        self.ps3 = PhaseShuffle(shift_factor)\n",
        "        self.ps4 = PhaseShuffle(shift_factor)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * model_size, 1)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "        x = self.ps1(x)\n",
        "\n",
        "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "        x = self.ps2(x)\n",
        "\n",
        "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "        x = self.ps3(x)\n",
        "\n",
        "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "        x = self.ps4(x)\n",
        "\n",
        "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "\n",
        "        x = x.view(-1, 256 * self.model_size)\n",
        "        if self.verbose:\n",
        "            print(x.shape)\n",
        "\n",
        "        return self.fc1(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLhKiDLWSntD",
        "colab_type": "text"
      },
      "source": [
        "norms.py  for images. May need to change this according to audio "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFUmSwyjRFaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sobolev_norm(input, s=1, c=5):\n",
        "    torch.cuda.empty_cache()\n",
        "    signal_ndim = 2\n",
        "    \n",
        "    #fourier transform of input -- [real, imaginary]\n",
        "    real_input = input\n",
        "    #print(real_input.shape)\n",
        "    imaginary_input = torch.zeros_like(input).cuda()\n",
        "    fourier_transform = torch.fft(torch.stack((real_input, imaginary_input), -1),\n",
        "                                  signal_ndim=signal_ndim)\n",
        "        \n",
        "    #compution the scale \\xi\n",
        "    #original N, M = fourier_transform.shape[2], fourier_transform.shape[2]\n",
        "\n",
        "    N, M = fourier_transform.shape[1], fourier_transform.shape[1]\n",
        "                                  \n",
        "    ns = torch.arange(0, N).type(torch.FloatTensor).cuda() / N\n",
        "    ms = torch.arange(0, M).type(torch.FloatTensor).cuda() / M\n",
        "                                  \n",
        "    xi_x, xi_y = torch.meshgrid([ms, ns])\n",
        "    squared_xi = xi_x[None, None, :, :] ** 2 +\\\n",
        "                 xi_y[None, None, :, :] ** 2\n",
        "    scaled_xi = (1 + c * squared_xi) ** (s * 0.5)\n",
        "\n",
        "    #print(scaled_xi.shape, scaled_xi.shape)\n",
        "    #print(fourier_transform.shape)\n",
        "    #print(torch.stack([scaled_xi, scaled_xi], -1).shape)\n",
        "\n",
        "    #the derivative in Sobolev norm is replaced by multiplication of \\xi and fourier transform\n",
        "    #print(fourier_transform.unsqueeze(0).unsqueeze(0).shape)\n",
        "\n",
        "\n",
        "    # derivative = torch.stack([scaled_xi, scaled_xi], -1) * fourier_transform  #ORIGINAL CODE\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    \n",
        "    #final inverse fourier transform\n",
        "    # output = torch.ifft(derivative, signal_ndim=signal_ndim)    #ORIGINAL CODE\n",
        "\n",
        "    output = torch.ifft((torch.stack([scaled_xi, scaled_xi], -1) * fourier_transform), signal_ndim=signal_ndim)  #modified code\n",
        "\n",
        "\n",
        "    \n",
        "    #we only need the real part as an answer\n",
        "    output = output[..., 0]\n",
        "    \n",
        "    return output\n",
        "\n",
        "def lp_norm(input, p=None):\n",
        "    input = input.view(input.size(0), -1).type(torch.FloatTensor)\n",
        "    \n",
        "    #in order to find stable norm the normalization is performed\n",
        "    #\\|x\\| = alpha * \\|(x / alpha)\\|\n",
        "    #we will also try to avoid zero elements in alpha\n",
        "    epsilon = 1e-5\n",
        "    \n",
        "    alpha, _ = torch.max((torch.abs(input) + epsilon), dim=1)\n",
        "    output = alpha * torch.norm(input / alpha[:, None], p=p, dim=1)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtqpwZgp9TM-",
        "colab_type": "text"
      },
      "source": [
        "# UTILITY FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVuzWlIR_dUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_console_logger(logger, verbose=False):\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    if verbose:\n",
        "        stream_handler.setLevel(logging.DEBUG)\n",
        "    else:\n",
        "        stream_handler.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('[%(levelname)s] %(message)s')\n",
        "    stream_handler.setFormatter(formatter)\n",
        "    file_handler = logging.FileHandler(\"model.log\")\n",
        "    logger.addHandler(stream_handler)\n",
        "    logger.addHandler(file_handler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Mfq8P09XVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_path(output_path):\n",
        "    if not os.path.isdir(output_path):\n",
        "        os.makedirs(output_path)\n",
        "    return output_path\n",
        "\n",
        "def numpy_to_var(numpy_data, cuda):\n",
        "    \"\"\"\n",
        "    Convert numpy array to Variable.\n",
        "    \"\"\"\n",
        "    data = numpy_data[:, np.newaxis, :]\n",
        "    data = torch.Tensor(data)\n",
        "    if cuda:\n",
        "        data = data.cuda()\n",
        "    return Variable(data, requires_grad=False)\n",
        "\n",
        "\n",
        "def plot_loss(D_cost_train, D_wass_train, D_cost_valid, D_wass_valid,\n",
        "              G_cost, save_path):\n",
        "    assert len(D_cost_train) == len(D_wass_train) == len(D_cost_valid) == len(D_wass_valid) == len(G_cost)\n",
        "\n",
        "    save_path = os.path.join(save_path, \"loss_curve.png\")\n",
        "\n",
        "    x = range(len(D_cost_train))\n",
        "\n",
        "    y1 = D_cost_train\n",
        "    y2 = D_wass_train\n",
        "    y3 = D_cost_valid\n",
        "    y4 = D_wass_valid\n",
        "    y5 = G_cost\n",
        "\n",
        "    plt.plot(x, y1, label='D_loss_train')\n",
        "    plt.plot(x, y2, label='D_wass_train')\n",
        "    plt.plot(x, y3, label='D_loss_valid')\n",
        "    plt.plot(x, y4, label='D_wass_valid')\n",
        "    plt.plot(x, y5, label='G_loss')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "\n",
        "#This is gradient penalty function from the original code. \n",
        "# Please make sure to insert proper comments regarding which gradient penalty is being applied\n",
        "#Considering that most of our project is based on that\n",
        "\n",
        "\n",
        "l2_norm = 2\n",
        "dual_norm = 1 / (1 - 1 / l2_norm) if l2_norm != 1 else np.inf\n",
        "\n",
        "c_for_sobolev = 5.0\n",
        "s_for_sobolev = 0\n",
        "\n",
        "def calc_gradient_penalty(net_dis, real_data, fake_data, batch_size, lmbda, use_cuda=False):\n",
        "    # Compute interpolation factors\n",
        "    alpha = torch.rand(batch_size, 1, 1)\n",
        "    alpha = alpha.expand(real_data.size())\n",
        "    alpha = alpha.cuda() if use_cuda else alpha\n",
        "\n",
        "    # Interpolate between real and fake data.\n",
        "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
        "    if use_cuda:\n",
        "        interpolates = interpolates.cuda()\n",
        "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
        "\n",
        "    # Evaluate discriminator\n",
        "    disc_interpolates = net_dis(interpolates)\n",
        "\n",
        "    \n",
        "\n",
        "    # Obtain gradients of the discriminator with respect to the inputs\n",
        "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else\n",
        "                              torch.ones(disc_interpolates.size()),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "\n",
        "    #============== LAMBDA GAMMA\n",
        "    dual_sobolev_gradients = sobolev_norm(gradients, s=-s_for_sobolev, c=c_for_sobolev)\n",
        "    gradients_norm = lp_norm(dual_sobolev_gradients, p=dual_norm)\n",
        "\n",
        "    lambda_ = lp_norm(sobolev_norm(real_data,  s=s_for_sobolev, c=c_for_sobolev),p=l2_norm).mean()\n",
        "    \n",
        "    \n",
        "    gamma_ = lp_norm(sobolev_norm(real_data, s=-s_for_sobolev, c=c_for_sobolev),p=dual_norm).mean()\n",
        "\n",
        "    prob_images = net_dis(real_data)\n",
        "\n",
        "    #==============\n",
        "\n",
        "    # Compute MSE between 1.0 and the gradient of the norm penalty to make discriminator\n",
        "    # to be a 1-Lipschitz function.\n",
        "    #gradient_penalty = lmbda * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    torch.cuda.empty_cache()\n",
        "    gradient_penalty = ((gradients_norm.float().cuda() / gamma_.float().cuda()  - 1) ** 2).mean() * lambda_.float().cuda()  + 1e-5 * (prob_images.float().cuda()  ** 2).mean()\n",
        "    \n",
        "    return gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE6FVnln-Jng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def save_samples(epoch_samples, epoch, output_dir, fs=16000):\n",
        "    \"\"\"\n",
        "    Save output samples.\n",
        "    \"\"\"\n",
        "    sample_dir = make_path(os.path.join(output_dir, str(epoch)))\n",
        "\n",
        "    for idx, sample in enumerate(epoch_samples):\n",
        "        output_path = os.path.join(sample_dir, \"{}.wav\".format(idx+1))\n",
        "        sample = sample[0]\n",
        "        librosa.output.write_wav(output_path, sample, fs)\n",
        "\n",
        "\n",
        "# Adapted from @jtcramer https://github.com/jtcramer/wavegan/blob/master/sample.py.  #og window length 16384\n",
        "def sample_generator(filepath, window_length=16384, fs=16000):\n",
        "    \"\"\"\n",
        "    Audio sample generator\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio_data, _ = librosa.load(filepath, sr=fs)\n",
        "\n",
        "        # Clip magnitude\n",
        "        max_mag = np.max(np.abs(audio_data))\n",
        "        if max_mag > 1:\n",
        "            audio_data /= max_mag\n",
        "    except Exception as e:\n",
        "        LOGGER.error(\"Could not load {}: {}\".format(filepath, str(e)))\n",
        "        raise StopIteration\n",
        "\n",
        "    # Pad audio to >= window_length.\n",
        "    audio_len = len(audio_data)\n",
        "    if audio_len < window_length:\n",
        "        pad_length = window_length - audio_len\n",
        "        left_pad = pad_length // 2\n",
        "        right_pad = pad_length - left_pad\n",
        "\n",
        "        audio_data = np.pad(audio_data, (left_pad, right_pad), mode='constant')\n",
        "        audio_len = len(audio_data)\n",
        "\n",
        "    while True:\n",
        "        if audio_len == window_length:\n",
        "            # If we only have a single 1*window_length audio, just yield.\n",
        "            sample = audio_data\n",
        "        else:\n",
        "            # Sample a random window from the audio\n",
        "            start_idx = np.random.randint(0, (audio_len - window_length) // 2)\n",
        "            end_idx = start_idx + window_length\n",
        "            sample = audio_data[start_idx:end_idx]\n",
        "\n",
        "        sample = sample.astype('float32')\n",
        "        assert not np.any(np.isnan(sample))\n",
        "\n",
        "        yield {'X': sample}\n",
        "\n",
        "\n",
        "def get_all_audio_filepaths(audio_dir):\n",
        "    return [os.path.join(root, fname)\n",
        "            for (root, dir_names, file_names) in os.walk(audio_dir, followlinks=True)\n",
        "            for fname in file_names\n",
        "            if (fname.lower().endswith('.wav') or fname.lower().endswith('.mp3'))]\n",
        "\n",
        "\n",
        "def batch_generator(audio_path_list, batch_size):\n",
        "    streamers = []\n",
        "    for audio_path in audio_path_list:\n",
        "        s = pescador.Streamer(sample_generator, audio_path)\n",
        "        streamers.append(s)\n",
        "\n",
        "    mux = pescador.ShuffledMux(streamers)\n",
        "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
        "\n",
        "    return batch_gen\n",
        "\n",
        "\n",
        "def split_data(audio_path_list, valid_ratio, test_ratio, batch_size):\n",
        "    num_files = len(audio_path_list)\n",
        "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
        "    num_test = int(np.ceil(num_files * test_ratio))\n",
        "    num_train = num_files - num_valid - num_test\n",
        "\n",
        "    if not (num_valid > 0 and num_test > 0 and num_train > 0):\n",
        "        LOGGER.error(\"Please download DATASET '{}' and put it under current path !\".format(DATASET_NAME))\n",
        "\n",
        "    # Random shuffle the audio_path_list for splitting.\n",
        "    random.shuffle(audio_path_list)\n",
        "\n",
        "    valid_files = audio_path_list[:num_valid]\n",
        "    test_files = audio_path_list[num_valid:num_valid + num_test]\n",
        "    train_files = audio_path_list[num_valid + num_test:]\n",
        "    train_size = len(train_files)\n",
        "\n",
        "    train_data = batch_generator(train_files, batch_size)\n",
        "    valid_data = batch_generator(valid_files, batch_size)\n",
        "    test_data = batch_generator(test_files, batch_size)\n",
        "\n",
        "    return train_data, valid_data, test_data, train_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vp9njaqTNR9",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Code blocks from **train.py** starts here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQgnWmO3SZga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =============Logger===============\n",
        "LOGGER = logging.getLogger('wavegan')\n",
        "LOGGER.setLevel(logging.DEBUG)\n",
        "\n",
        "LOGGER.info('Initialized logger.')\n",
        "init_console_logger(LOGGER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv5PttYPTEuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =============Parameters===============\n",
        "# args = parse_arguments()\n",
        "# epochs = args['num_epochs']\n",
        "# batch_size = args['batch_size']\n",
        "# latent_dim = args['latent_dim']\n",
        "# ngpus = args['ngpus']\n",
        "# model_size = args['model_size']\n",
        "# model_dir = make_path(os.path.join(args['output_dir'],\n",
        "#                                    datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")))\n",
        "# args['model_dir'] = model_dir\n",
        "# # save samples for every N epochs.\n",
        "# epochs_per_sample = args['epochs_per_sample']\n",
        "# # gradient penalty regularization factor.\n",
        "# lmbda = args['lmbda']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFz7CHULfqD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MANUALLY ADDING ARGUMENTS\n",
        "\n",
        "model_size= 8                          #'Model size parameter used in WaveGAN' default=64,\n",
        "shift_factor= 2                         #default=2, 'Maximum shift used by phase shuffle'\n",
        "batch_shuffle=True\n",
        "verbose=False\n",
        "post_proc_filt_len=512                  #default=512 Length of post processing filter used by generator. Set to 0 to disable.'\n",
        "alpha= 0.2                              #Slope of negative part of LReLU used by discriminator\n",
        "valid_ratio=0.1                          #Ratio of audio files used for validation\n",
        "test_ratio=0.1\n",
        "batch_size= 1\n",
        "epochs= 60\n",
        "ngpus=1\n",
        "latent_dim= 100                         #Size of latent dimension used by generator\n",
        "epochs_per_sample=10                     #How many epochs between every set of samples generated for inspection\n",
        "sample_size= 10                         # Generate 10 samples every sample generation.\n",
        "lmbda=10.0                                  #Gradient penalty regularization factor default=10\n",
        "learning_rate=1e-4\n",
        "beta1=0.5\n",
        "beta2=0.9\n",
        "audio_dir='/content/drive/My Drive/WaveGANpy/piano'\n",
        "output_dir= '/content/drive/My Drive/WaveGANpy/piano_outputBanachsize8/'  #<---------------Need to set whatever /content/file\n",
        "\n",
        "DATASET_NAME='piano'\n",
        "\n",
        "#=====just trying out stuff\n",
        "#v=True\n",
        "#psb=True\n",
        "\n",
        "\n",
        "#==============================\n",
        "\n",
        "#    parser.add_argument('-v', '--verbose', dest='verbose', action='store_true')   \n",
        "# Had no clue what to do with --verbose, I suspect its something to do with logging\n",
        "\n",
        "#parser.add_argument('-psb', '--phase-shuffle-batchwise', dest='batch_shuffle', action='store_true',help='If true, apply phase shuffle to entire batches rather than individual samples')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKFdvHv7Vqpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dir   #might also need to change the .pkl to .pth or whatever kind of network saving method we want to use\n",
        "#Lets talk about .pkl, .pth , .etc choices whenever we come across this comment\n",
        "\n",
        "#audio_dir = args['audio_dir']\n",
        "#output_dir = args['output_dir']\n",
        "\n",
        "netD_path = os.path.join(output_dir, \"discriminator.pth\")\n",
        "netG_path = os.path.join(output_dir, \"generator.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGQ6xYp0WoG_",
        "colab_type": "text"
      },
      "source": [
        "Initializing Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUUk4ExZWsoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =============Network===============\n",
        "netG = WaveGANGenerator(model_size=model_size, ngpus=ngpus, latent_dim=latent_dim, upsample=True)\n",
        "netD = WaveGANDiscriminator(model_size=model_size, ngpus=ngpus)\n",
        "\n",
        "if cuda:\n",
        "    netG = torch.nn.DataParallel(netG).cuda()\n",
        "    netD = torch.nn.DataParallel(netD).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_grMkq8W_OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading weights from saved models (optional)\n",
        "#Dipam seriously need to introduce better checkpointing to this code. \n",
        "#Also need to check whether this thing is even loading actual weights or some bullshit that just restarts the process from zero\n",
        "#Please do not forget to remove my weird comments \n",
        "\n",
        "# netG.load_state_dict(torch.load(netG_path))\n",
        "# netD.load_state_dict(torch.load(netD_path))\n",
        "\n",
        "# netG.load_state_dict(torch.load(netG_path)['model_state_dict'])\n",
        "# netD.load_state_dict(torch.load(netD_path)['model_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGybQHU5YDOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialization of Optimizers. \n",
        "#Need to check out what the hell this TTUR rule is. \n",
        "\n",
        "\n",
        "# \"Two time-scale update rule\"(TTUR) to update netD 4x faster than netG.\n",
        "\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(beta1, beta2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pf9vRx-YqH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample noise used for generated output.\n",
        "sample_noise = torch.randn(sample_size, latent_dim)\n",
        "if cuda:\n",
        "    sample_noise = sample_noise.cuda()\n",
        "sample_noise_Var = autograd.Variable(sample_noise, requires_grad=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8YJohZJcYWI",
        "colab_type": "code",
        "outputId": "578053a5-2170-4aa7-f2cc-413b72e1f00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "check_memory()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4117504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1IEPpVM0QK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save config.\n",
        "# LOGGER.info('Saving configurations...')\n",
        "# config_path = os.path.join(model_dir, 'config.json')\n",
        "# with open(config_path, 'w') as f:\n",
        "#     json.dump(args, f)\n",
        "\n",
        "#THIS CODE CELL CONTAINS SOME args nonsense... need to remove it considering we have removed the argparse thing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBysqih63v96",
        "colab_type": "code",
        "outputId": "0e9d0e99-7ac6-435f-848e-bc66efef91a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/WaveGANpy/piano_outputst/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "discriminator_50.pth  generator_50.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfrTCQqXZRIc",
        "colab_type": "text"
      },
      "source": [
        "Loading data  \n",
        "* (will need to clean out args and configure it to read /drive/content)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3svam9kpZNS4",
        "colab_type": "code",
        "outputId": "b7766033-0460-401d-bf4b-c98efa8d04e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load data.\n",
        "LOGGER.info('Loading audio data...')\n",
        "audio_paths = get_all_audio_filepaths(audio_dir)\n",
        "train_data, valid_data, test_data, train_size = split_data(audio_paths, valid_ratio, test_ratio, batch_size)\n",
        "TOTAL_TRAIN_SAMPLES = train_size\n",
        "BATCH_NUM = TOTAL_TRAIN_SAMPLES // batch_size\n",
        "print(TOTAL_TRAIN_SAMPLES, BATCH_NUM)\n",
        "\n",
        "train_iter = iter(train_data)\n",
        "valid_iter = iter(valid_data)\n",
        "test_iter = iter(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading audio data...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F2iDKlLSWtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOqnn097IIU8",
        "colab_type": "text"
      },
      "source": [
        "How to prevent Google Colab from disconnecting ?\n",
        "\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_ML8KjPZuBK",
        "colab_type": "text"
      },
      "source": [
        "Actual Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHJf2ifTXpEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC8YLEA9denO",
        "colab_type": "code",
        "outputId": "9e7781ec-9e4c-4751-fc57-9544c0152eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "check_memory()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4117504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4R4katOUiEg",
        "colab_type": "code",
        "outputId": "152de72c-549b-44e3-d3fb-4ad6760518a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# =============Train===============\n",
        "history = []\n",
        "D_costs_train = []\n",
        "D_wasses_train = []\n",
        "D_costs_valid = []\n",
        "D_wasses_valid = []\n",
        "G_costs = []\n",
        "\n",
        "start = time.time()\n",
        "LOGGER.info('Starting training...EPOCHS={}, BATCH_SIZE={}, BATCH_NUM={}'.format(epochs, batch_size, BATCH_NUM))\n",
        "for epoch in range(1, epochs+1):\n",
        "    # print(\"Entered\")\n",
        "    LOGGER.info(\"{} Epoch: {}/{}\".format(time_since(start), epoch, epochs))\n",
        "\n",
        "    D_cost_train_epoch = []\n",
        "    D_wass_train_epoch = []\n",
        "    D_cost_valid_epoch = []\n",
        "    D_wass_valid_epoch = []\n",
        "    G_cost_epoch = []\n",
        "    # pdb.set_trace()\n",
        "    for i in range(1, BATCH_NUM+1):\n",
        "        # print(\"Second\")\n",
        "        # Set Discriminator parameters to require gradients.\n",
        "        for p in netD.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        one = torch.tensor(1, dtype=torch.float)\n",
        "        neg_one = one * -1\n",
        "        if cuda:\n",
        "            one = one.cuda()\n",
        "            neg_one = neg_one.cuda()\n",
        "        #############################\n",
        "        # (1) Train Discriminator\n",
        "        #############################\n",
        "        for iter_dis in range(5):\n",
        "            netD.zero_grad()\n",
        "\n",
        "            # Noise\n",
        "            noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
        "            if cuda:\n",
        "                noise = noise.cuda()\n",
        "            noise_Var = Variable(noise, requires_grad=False)\n",
        "\n",
        "            real_data_Var = numpy_to_var(next(train_iter)['X'], cuda)\n",
        "\n",
        "            # a) compute loss contribution from real training data\n",
        "            D_real = netD(real_data_Var)\n",
        "            D_real = D_real.mean()  # avg loss\n",
        "            D_real.backward(neg_one)  # loss * -1\n",
        "\n",
        "            # b) compute loss contribution from generated data, then backprop.\n",
        "            fake = autograd.Variable(netG(noise_Var).data)\n",
        "            D_fake = netD(fake)\n",
        "            D_fake = D_fake.mean()\n",
        "            D_fake.backward(one)\n",
        "\n",
        "            # c) compute gradient penalty and backprop\n",
        "            gradient_penalty = calc_gradient_penalty(netD, real_data_Var.data,\n",
        "                                                     fake.data, batch_size, lmbda,\n",
        "                                                     use_cuda=cuda)\n",
        "            gradient_penalty.backward(one)\n",
        "\n",
        "            # Compute cost * Wassertein loss..\n",
        "            D_cost_train = D_fake - D_real + gradient_penalty\n",
        "            D_wass_train = D_real - D_fake\n",
        "\n",
        "            # Update gradient of discriminator.\n",
        "            optimizerD.step()\n",
        "\n",
        "            #############################\n",
        "            # (2) Compute Valid data\n",
        "            #############################\n",
        "            netD.zero_grad()\n",
        "\n",
        "            valid_data_Var = numpy_to_var(next(valid_iter)['X'], cuda)\n",
        "            D_real_valid = netD(valid_data_Var)\n",
        "            D_real_valid = D_real_valid.mean()  # avg loss\n",
        "\n",
        "            # b) compute loss contribution from generated data, then backprop.\n",
        "            fake_valid = netG(noise_Var)\n",
        "            D_fake_valid = netD(fake_valid)\n",
        "            D_fake_valid = D_fake_valid.mean()\n",
        "\n",
        "            # c) compute gradient penalty and backprop\n",
        "            gradient_penalty_valid = calc_gradient_penalty(netD, valid_data_Var.data,\n",
        "                                                           fake_valid.data, batch_size, lmbda,\n",
        "                                                           use_cuda=cuda)\n",
        "            # Compute metrics and record in batch history.\n",
        "            D_cost_valid = D_fake_valid - D_real_valid + gradient_penalty_valid\n",
        "            D_wass_valid = D_real_valid - D_fake_valid\n",
        "\n",
        "            if cuda:\n",
        "                D_cost_train = D_cost_train.cpu()\n",
        "                D_wass_train = D_wass_train.cpu()\n",
        "                D_cost_valid = D_cost_valid.cpu()\n",
        "                D_wass_valid = D_wass_valid.cpu()\n",
        "\n",
        "            # Record costs\n",
        "            D_cost_train_epoch.append(D_cost_train.data.numpy())\n",
        "            D_wass_train_epoch.append(D_wass_train.data.numpy())\n",
        "            D_cost_valid_epoch.append(D_cost_valid.data.numpy())\n",
        "            D_wass_valid_epoch.append(D_wass_valid.data.numpy())\n",
        "\n",
        "        #############################\n",
        "        # (3) Train Generator\n",
        "        #############################\n",
        "        # Prevent discriminator update.\n",
        "        for p in netD.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # Reset generator gradients\n",
        "        netG.zero_grad()\n",
        "\n",
        "        # Noise\n",
        "        noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
        "        if cuda:\n",
        "            noise = noise.cuda()\n",
        "        noise_Var = Variable(noise, requires_grad=False)\n",
        "\n",
        "        fake = netG(noise_Var)\n",
        "        G = netD(fake)\n",
        "        G = G.mean()\n",
        "\n",
        "        # Update gradients.\n",
        "        G.backward(neg_one)\n",
        "        G_cost = -G\n",
        "\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Record costs\n",
        "        if cuda:\n",
        "            G_cost = G_cost.cpu()\n",
        "        G_cost_epoch.append(G_cost.data.numpy())\n",
        "\n",
        "        if i % (BATCH_NUM // 5) == 0:\n",
        "            LOGGER.info(\"{} Epoch={} Batch: {}/{} D_c:{:.4f} | D_w:{:.4f} | G:{:.4f}\".format(time_since(start), epoch,\n",
        "                                                                                             i, BATCH_NUM,\n",
        "                                                                                             D_cost_train.data.numpy(),\n",
        "                                                                                             D_wass_train.data.numpy(),\n",
        "                                                                                             G_cost.data.numpy()))\n",
        "                                                                                             \n",
        "                                                                             \n",
        "\n",
        "    # Save the average cost of batches in every epoch.\n",
        "    D_cost_train_epoch_avg = sum(D_cost_train_epoch) / float(len(D_cost_train_epoch))\n",
        "    D_wass_train_epoch_avg = sum(D_wass_train_epoch) / float(len(D_wass_train_epoch))\n",
        "    D_cost_valid_epoch_avg = sum(D_cost_valid_epoch) / float(len(D_cost_valid_epoch))\n",
        "    D_wass_valid_epoch_avg = sum(D_wass_valid_epoch) / float(len(D_wass_valid_epoch))\n",
        "    G_cost_epoch_avg = sum(G_cost_epoch) / float(len(G_cost_epoch))\n",
        "\n",
        "    D_costs_train.append(D_cost_train_epoch_avg)\n",
        "    D_wasses_train.append(D_wass_train_epoch_avg)\n",
        "    D_costs_valid.append(D_cost_valid_epoch_avg)\n",
        "    D_wasses_valid.append(D_wass_valid_epoch_avg)\n",
        "    G_costs.append(G_cost_epoch_avg)\n",
        "\n",
        "    LOGGER.info(\"{} D_cost_train:{:.4f} | D_wass_train:{:.4f} | D_cost_valid:{:.4f} | D_wass_valid:{:.4f} | \"\n",
        "                \"G_cost:{:.4f}\".format(time_since(start),\n",
        "                                       D_cost_train_epoch_avg,\n",
        "                                       D_wass_train_epoch_avg,\n",
        "                                       D_cost_valid_epoch_avg,\n",
        "                                       D_wass_valid_epoch_avg,\n",
        "                                       G_cost_epoch_avg))\n",
        "\n",
        "    # Generate audio samples.\n",
        "    if epoch % epochs_per_sample == 0:\n",
        "        LOGGER.info(\"Generating samples...\")\n",
        "        sample_out = netG(sample_noise_Var)\n",
        "        if cuda:\n",
        "            sample_out = sample_out.cpu()\n",
        "        sample_out = sample_out.data.numpy()\n",
        "        save_samples(sample_out, epoch, output_dir)\n",
        "        LOGGER.info(\"Saving models...\")\n",
        "        netD_path = os.path.join(output_dir, \"discriminator.pth\")\n",
        "        netG_path = os.path.join(output_dir, \"generator.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': netD.state_dict(),\n",
        "            'optimizer_state_dict': optimizerD.state_dict()\n",
        "            \n",
        "            \n",
        "            }, netD_path)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': netG.state_dict(),\n",
        "            'optimizer_state_dict': optimizerG.state_dict()}, netG_path)\n",
        "\n",
        "        \n",
        "        \n",
        "     \n",
        "\n",
        "    # TODO\n",
        "    # Early stopping by Inception Score(IS)\n",
        "\n",
        "LOGGER.info('>>>>>>>Training finished !<<<<<<<')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Starting training...EPOCHS=60, BATCH_SIZE=1, BATCH_NUM=15\n",
            "[INFO] 0m 0s Epoch: 1/60\n",
            "[INFO] 2m 53s Epoch=1 Batch: 3/15 D_c:1.2737 | D_w:3.6486 | G:0.1720\n",
            "[INFO] 5m 8s Epoch=1 Batch: 6/15 D_c:-13.8438 | D_w:13.8533 | G:-0.5596\n",
            "[INFO] 7m 7s Epoch=1 Batch: 9/15 D_c:7.7469 | D_w:-7.5185 | G:-23.6588\n",
            "[INFO] 9m 2s Epoch=1 Batch: 12/15 D_c:12.8275 | D_w:-11.7037 | G:-13.5089\n",
            "[INFO] 10m 56s Epoch=1 Batch: 15/15 D_c:-24.8375 | D_w:27.9325 | G:39.3182\n",
            "[INFO] 10m 56s D_cost_train:2.4720 | D_wass_train:0.2573 | D_cost_valid:0.1980 | D_wass_valid:1.6306 | G_cost:-3.3814\n",
            "[INFO] 10m 56s Epoch: 2/60\n",
            "[INFO] 12m 51s Epoch=2 Batch: 3/15 D_c:-26.0861 | D_w:26.3356 | G:55.4477\n",
            "[INFO] 14m 45s Epoch=2 Batch: 6/15 D_c:16.5906 | D_w:-15.4196 | G:9.7281\n",
            "[INFO] 16m 40s Epoch=2 Batch: 9/15 D_c:4.2979 | D_w:-0.2684 | G:6.9392\n",
            "[INFO] 18m 34s Epoch=2 Batch: 12/15 D_c:-28.9577 | D_w:29.0271 | G:16.5062\n",
            "[INFO] 20m 29s Epoch=2 Batch: 15/15 D_c:-68.6876 | D_w:75.0842 | G:31.0052\n",
            "[INFO] 20m 29s D_cost_train:-13.2635 | D_wass_train:17.1496 | D_cost_valid:-13.2372 | D_wass_valid:19.1314 | G_cost:27.0622\n",
            "[INFO] 20m 29s Epoch: 3/60\n",
            "[INFO] 22m 23s Epoch=3 Batch: 3/15 D_c:-71.6860 | D_w:134.1292 | G:41.4436\n",
            "[INFO] 24m 18s Epoch=3 Batch: 6/15 D_c:-12.1090 | D_w:55.4828 | G:-5.4060\n",
            "[INFO] 26m 13s Epoch=3 Batch: 9/15 D_c:18.4991 | D_w:-15.8780 | G:-11.2042\n",
            "[INFO] 28m 8s Epoch=3 Batch: 12/15 D_c:-32.9486 | D_w:34.9666 | G:135.5516\n",
            "[INFO] 30m 2s Epoch=3 Batch: 15/15 D_c:1.1475 | D_w:0.3388 | G:72.0135\n",
            "[INFO] 30m 2s D_cost_train:-26.2937 | D_wass_train:45.7119 | D_cost_valid:-17.3104 | D_wass_valid:46.9982 | G_cost:45.5778\n",
            "[INFO] 30m 2s Epoch: 4/60\n",
            "[INFO] 31m 57s Epoch=4 Batch: 3/15 D_c:-12.8701 | D_w:13.4004 | G:7.5853\n",
            "[INFO] 33m 51s Epoch=4 Batch: 6/15 D_c:-5.3459 | D_w:6.9755 | G:-7.8055\n",
            "[INFO] 35m 45s Epoch=4 Batch: 9/15 D_c:-5.2334 | D_w:6.4850 | G:42.9145\n",
            "[INFO] 37m 38s Epoch=4 Batch: 12/15 D_c:-6.8298 | D_w:7.1423 | G:51.6958\n",
            "[INFO] 39m 32s Epoch=4 Batch: 15/15 D_c:-10.0490 | D_w:11.1554 | G:-6.4706\n",
            "[INFO] 39m 32s D_cost_train:-3.8135 | D_wass_train:6.3984 | D_cost_valid:-1.9612 | D_wass_valid:6.7775 | G_cost:22.8543\n",
            "[INFO] 39m 32s Epoch: 5/60\n",
            "[INFO] 41m 25s Epoch=5 Batch: 3/15 D_c:-3.7332 | D_w:3.9228 | G:5.7107\n",
            "[INFO] 43m 18s Epoch=5 Batch: 6/15 D_c:-4.6102 | D_w:8.7736 | G:59.5830\n",
            "[INFO] 45m 8s Epoch=5 Batch: 9/15 D_c:-1.7179 | D_w:7.2191 | G:-3.9100\n",
            "[INFO] 46m 56s Epoch=5 Batch: 12/15 D_c:-9.8005 | D_w:10.4305 | G:55.6094\n",
            "[INFO] 48m 43s Epoch=5 Batch: 15/15 D_c:-4.8041 | D_w:5.2975 | G:21.3293\n",
            "[INFO] 48m 43s D_cost_train:-3.0721 | D_wass_train:5.2209 | D_cost_valid:-0.6699 | D_wass_valid:5.3567 | G_cost:29.0904\n",
            "[INFO] 48m 43s Epoch: 6/60\n",
            "[INFO] 50m 31s Epoch=6 Batch: 3/15 D_c:-8.7305 | D_w:8.7505 | G:-10.0573\n",
            "[INFO] 52m 18s Epoch=6 Batch: 6/15 D_c:-26.3042 | D_w:27.0391 | G:109.0467\n",
            "[INFO] 54m 8s Epoch=6 Batch: 9/15 D_c:-7.5783 | D_w:7.6291 | G:36.0318\n",
            "[INFO] 56m 1s Epoch=6 Batch: 12/15 D_c:-6.7096 | D_w:9.6845 | G:3.8844\n",
            "[INFO] 57m 54s Epoch=6 Batch: 15/15 D_c:-24.6671 | D_w:25.4789 | G:115.8630\n",
            "[INFO] 57m 54s D_cost_train:-4.7881 | D_wass_train:7.6794 | D_cost_valid:-3.4170 | D_wass_valid:7.8751 | G_cost:40.2267\n",
            "[INFO] 57m 54s Epoch: 7/60\n",
            "[INFO] 59m 48s Epoch=7 Batch: 3/15 D_c:-11.9499 | D_w:12.6409 | G:33.7535\n",
            "[INFO] 61m 42s Epoch=7 Batch: 6/15 D_c:-1.5096 | D_w:14.0013 | G:6.6420\n",
            "[INFO] 63m 37s Epoch=7 Batch: 9/15 D_c:4.8508 | D_w:2.7398 | G:48.5023\n",
            "[INFO] 65m 31s Epoch=7 Batch: 12/15 D_c:-18.6482 | D_w:20.2613 | G:104.9133\n",
            "[INFO] 67m 25s Epoch=7 Batch: 15/15 D_c:-17.8443 | D_w:22.3939 | G:30.1951\n",
            "[INFO] 67m 25s D_cost_train:-9.5145 | D_wass_train:12.7136 | D_cost_valid:-3.5465 | D_wass_valid:9.7723 | G_cost:48.0207\n",
            "[INFO] 67m 25s Epoch: 8/60\n",
            "[INFO] 69m 20s Epoch=8 Batch: 3/15 D_c:-20.1787 | D_w:20.4196 | G:88.8772\n",
            "[INFO] 71m 15s Epoch=8 Batch: 6/15 D_c:-10.4254 | D_w:13.1526 | G:62.7608\n",
            "[INFO] 73m 9s Epoch=8 Batch: 9/15 D_c:-23.3573 | D_w:26.5488 | G:101.3034\n",
            "[INFO] 75m 3s Epoch=8 Batch: 12/15 D_c:-29.3762 | D_w:29.7219 | G:86.0218\n",
            "[INFO] 76m 56s Epoch=8 Batch: 15/15 D_c:-19.4623 | D_w:26.8307 | G:106.1296\n",
            "[INFO] 76m 56s D_cost_train:-12.5965 | D_wass_train:17.0184 | D_cost_valid:-4.5809 | D_wass_valid:11.9819 | G_cost:80.4005\n",
            "[INFO] 76m 56s Epoch: 9/60\n",
            "[INFO] 78m 50s Epoch=9 Batch: 3/15 D_c:-41.0367 | D_w:41.6224 | G:117.8442\n",
            "[INFO] 80m 46s Epoch=9 Batch: 6/15 D_c:-41.0166 | D_w:46.6079 | G:110.5275\n",
            "[INFO] 82m 42s Epoch=9 Batch: 9/15 D_c:-39.5912 | D_w:41.8665 | G:123.3260\n",
            "[INFO] 84m 37s Epoch=9 Batch: 12/15 D_c:-23.8363 | D_w:31.0683 | G:106.3445\n",
            "[INFO] 86m 33s Epoch=9 Batch: 15/15 D_c:-17.7368 | D_w:27.9060 | G:101.9127\n",
            "[INFO] 86m 33s D_cost_train:-23.8143 | D_wass_train:33.7258 | D_cost_valid:-3.1324 | D_wass_valid:19.2891 | G_cost:113.1862\n",
            "[INFO] 86m 33s Epoch: 10/60\n",
            "[INFO] 88m 29s Epoch=10 Batch: 3/15 D_c:-34.1364 | D_w:38.9744 | G:127.5216\n",
            "[INFO] 90m 25s Epoch=10 Batch: 6/15 D_c:12.6166 | D_w:11.7406 | G:110.0829\n",
            "[INFO] 92m 21s Epoch=10 Batch: 9/15 D_c:-42.2198 | D_w:46.4548 | G:135.7744\n",
            "[INFO] 94m 16s Epoch=10 Batch: 12/15 D_c:-42.7727 | D_w:58.1620 | G:116.2976\n",
            "[INFO] 96m 12s Epoch=10 Batch: 15/15 D_c:-19.5941 | D_w:57.9918 | G:138.7635\n",
            "[INFO] 96m 12s D_cost_train:-29.4209 | D_wass_train:42.4815 | D_cost_valid:-8.0669 | D_wass_valid:25.7464 | G_cost:121.0676\n",
            "[INFO] Generating samples...\n",
            "[INFO] Saving models...\n",
            "[INFO] 96m 13s Epoch: 11/60\n",
            "[INFO] 98m 8s Epoch=11 Batch: 3/15 D_c:-13.8751 | D_w:45.9989 | G:140.3988\n",
            "[INFO] 100m 4s Epoch=11 Batch: 6/15 D_c:40.6066 | D_w:20.4406 | G:135.4169\n",
            "[INFO] 101m 59s Epoch=11 Batch: 9/15 D_c:-32.1170 | D_w:39.9100 | G:145.2431\n",
            "[INFO] 103m 55s Epoch=11 Batch: 12/15 D_c:-48.0911 | D_w:71.3106 | G:176.2660\n",
            "[INFO] 105m 50s Epoch=11 Batch: 15/15 D_c:-62.3055 | D_w:64.9060 | G:110.6952\n",
            "[INFO] 105m 50s D_cost_train:-36.2406 | D_wass_train:57.0140 | D_cost_valid:-9.4178 | D_wass_valid:35.1851 | G_cost:138.1649\n",
            "[INFO] 105m 50s Epoch: 12/60\n",
            "[INFO] 107m 45s Epoch=12 Batch: 3/15 D_c:-60.2861 | D_w:68.5445 | G:187.5557\n",
            "[INFO] 109m 40s Epoch=12 Batch: 6/15 D_c:-62.6978 | D_w:69.9388 | G:126.7139\n",
            "[INFO] 111m 35s Epoch=12 Batch: 9/15 D_c:-62.5611 | D_w:67.3204 | G:160.7236\n",
            "[INFO] 113m 31s Epoch=12 Batch: 12/15 D_c:-6.2282 | D_w:53.2397 | G:203.8840\n",
            "[INFO] 115m 26s Epoch=12 Batch: 15/15 D_c:-22.2956 | D_w:34.4911 | G:93.8691\n",
            "[INFO] 115m 26s D_cost_train:-40.8335 | D_wass_train:64.4052 | D_cost_valid:-8.8890 | D_wass_valid:39.7241 | G_cost:148.6563\n",
            "[INFO] 115m 26s Epoch: 13/60\n",
            "[INFO] 117m 21s Epoch=13 Batch: 3/15 D_c:-9.4714 | D_w:29.0706 | G:96.3951\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crvAjhUsaI9I",
        "colab_type": "text"
      },
      "source": [
        "Plotting loss and saving the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnDCH3gFZ-LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_loss(D_costs_train, D_wasses_train,D_costs_valid, D_wasses_valid, G_costs, output_dir)\n",
        "\n",
        "torch.save(netD.state_dict(), netD_path)\n",
        "torch.save(netG.state_dict(), netG_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}